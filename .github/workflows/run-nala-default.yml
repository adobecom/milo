name: Run Nala Tests

on:
  push:
    branches:
      - stage
      - main
  pull_request:
    branches:
      - stage
      - main
    types: [opened, synchronize, reopened]
  
  workflow_dispatch:
    inputs:
      max_shards:
        description: 'Maximum number of parallel shards (2-10)'
        required: false
        default: '6'
        type: string

jobs:
  # Calculate optimal shard count based on test files
  calculate-shards:
    name: Calculate Test Shards
    runs-on: ubuntu-latest
    outputs:
      shard-count: ${{ steps.calculate.outputs.count }}
      matrix: ${{ steps.calculate.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Setup Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Restore test timing data
        uses: actions/cache@v3
        with:
          path: test-timings.json
          key: test-timings-v1-${{ github.sha }}
          restore-keys: |
            test-timings-v1-
      
      - name: Check timing data
        run: |
          if [ -f test-timings.json ]; then
            echo "Successfully loaded previous timing data"
            echo "File size: $(stat -f%z test-timings.json 2>/dev/null || stat -c%s test-timings.json) bytes"
          else
            echo "No previous timing data found, will use count-based distribution"
          fi

      - name: Calculate optimal shard count
        id: calculate
        run: |
          # Count test files
          TEST_COUNT=$(find nala -name "*.test.js" | wc -l)
          echo "Found $TEST_COUNT test files"
          
          # Get max shards from input (default to 6 for auto runs)
          MAX_SHARDS=${{ inputs.max_shards }}
          MAX_SHARDS=${MAX_SHARDS:-6}
          
          # Check if we have timing data for weighted distribution
          if [ -f test-timings.json ]; then
            echo "Using weighted distribution based on test execution times"
            
            # Calculate weighted shards
            node nala/utils/calculate-weighted-shards.js \
              --timing-data test-timings.json \
              --max-shards $MAX_SHARDS \
              --output shard-assignments.json
            
            # Extract shard count from output
            OPTIMAL_SHARDS=$(jq -r '.shardCount' shard-assignments.json)
            
            # Generate distribution summary
            echo "## Test Sharding Configuration (Weighted)" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Distribution by Shard:" >> $GITHUB_STEP_SUMMARY
            echo "| Shard | Tests | Duration |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|-------|----------|" >> $GITHUB_STEP_SUMMARY
            
            # Add distribution details
            jq -r '.distribution[] | "| \(.shard) | \(.testCount) | \(.duration)s |"' shard-assignments.json >> $GITHUB_STEP_SUMMARY
          else
            echo "No timing data found, using count-based distribution"
            
            # Calculate optimal shard count (5-8 test files per shard)
            OPTIMAL_SHARDS=$((TEST_COUNT / 6))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS < 2 ? 2 : OPTIMAL_SHARDS))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS > MAX_SHARDS ? MAX_SHARDS : OPTIMAL_SHARDS))
            
            echo "## Test Sharding Configuration" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "- **Tests per shard:** ~$((TEST_COUNT / OPTIMAL_SHARDS))" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "Using $OPTIMAL_SHARDS shards for $TEST_COUNT test files"
          echo "count=$OPTIMAL_SHARDS" >> $GITHUB_OUTPUT
          
          # Create matrix JSON
          SHARDS_JSON=""
          for i in $(seq 1 $OPTIMAL_SHARDS); do
            if [ $i -eq 1 ]; then
              SHARDS_JSON="$i"
            else
              SHARDS_JSON="$SHARDS_JSON,$i"
            fi
          done
          MATRIX="{\"shard\":[$SHARDS_JSON]}"
          echo "Debug: Generated matrix: $MATRIX"
          printf "matrix=%s\n" "$MATRIX" >> $GITHUB_OUTPUT
          
          # Debug: Check if shard-assignments.json exists
          if [ -f shard-assignments.json ]; then
            echo "‚úì shard-assignments.json created successfully"
            echo "File size: $(stat -f%z shard-assignments.json 2>/dev/null || stat -c%s shard-assignments.json) bytes"
          else
            echo "‚úó shard-assignments.json not found"
          fi

      - name: Upload shard assignments
        if: success() && hashFiles('shard-assignments.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: shard-assignments
          path: shard-assignments.json
          retention-days: 1
          if-no-files-found: warn

  # Purge branch before running tests
  purge-branch:
    name: Purge Branch Cache
    runs-on: ubuntu-latest
    steps:
      - name: Purge branch
        run: |
          # Determine branch name based on event type
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            FEATURE_BRANCH="${{ github.event.pull_request.head.ref }}"
            ORG="${{ github.event.pull_request.head.repo.owner.login }}"
            REPO="${{ github.event.pull_request.head.repo.name }}"
          else
            # For push events (main/stage)
            FEATURE_BRANCH="${{ github.ref_name }}"
            ORG="${{ github.repository_owner }}"
            REPO="${{ github.event.repository.name }}"
          fi
          
          # Replace "/" characters in branch name with "-"
          FEATURE_BRANCH=$(echo "$FEATURE_BRANCH" | sed 's/\//-/g')
          
          echo "Event: ${{ github.event_name }}"
          echo "Organization: $ORG"
          echo "Repository: $REPO"
          echo "Branch: $FEATURE_BRANCH"
          
          # Skip purge for main branch (it doesn't need purging)
          if [[ "$FEATURE_BRANCH" == "main" ]]; then
            echo "‚ÑπÔ∏è Skipping purge for main branch"
            exit 0
          fi
          
          echo "Purging branch: $FEATURE_BRANCH"
          PURGE_URL="https://admin.hlx.page/code/$ORG/$REPO/$FEATURE_BRANCH/*"
          
          echo "Executing: curl -si -X POST \"$PURGE_URL\""
          PURGE_RESPONSE=$(curl -si -X POST "$PURGE_URL")
          
          # Check if the purge was successful
          if echo "$PURGE_RESPONSE" | grep -q "202"; then
            echo "‚úÖ Branch $FEATURE_BRANCH successfully purged"
            echo "Waiting 10 seconds for purge to complete..."
            sleep 10
          else
            echo "‚ùå Failed to purge branch $FEATURE_BRANCH"
            echo "Response: $PURGE_RESPONSE"
            # Don't fail the workflow if purge fails, just warn
            echo "::warning::Branch purge failed but continuing with tests"
          fi

  # Build Docker image with dependency caching
  build-test-image:
    name: Build Test Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
      deps-tag: ${{ steps.deps-tag.outputs.tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate image metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}/nala-tests
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}

      - name: Check if image exists
        id: check
        run: |
          # Get the deps tag to check if we need to rebuild
          DEPS_TAG="ghcr.io/${{ github.repository }}/nala-tests:deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "Checking for existing image: $DEPS_TAG"
          
          if docker manifest inspect $DEPS_TAG > /dev/null 2>&1; then
            echo "Image exists with current dependencies, skipping build"
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "existing_tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          else
            echo "Image not found or dependencies changed, building new image"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Build and push Docker image
        if: steps.check.outputs.exists != 'true'
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.nala
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PLAYWRIGHT_VERSION=1.54.2

      - name: Export image reference
        id: deps-tag
        run: |
          DEPS_TAG="deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          
          if [[ "${{ steps.check.outputs.exists }}" == "true" ]]; then
            echo "IMAGE_REF=${{ steps.check.outputs.existing_tag }}" >> $GITHUB_ENV
          else
            echo "IMAGE_REF=ghcr.io/${{ github.repository }}/nala-tests@${{ steps.build.outputs.digest }}" >> $GITHUB_ENV
          fi
          echo "Using image: $IMAGE_REF"

  # Parallel test execution using the cached image
  run-nala-tests:
    name: E2E Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
    needs: [calculate-shards, build-test-image, purge-branch]
    if: always() && !cancelled() && needs.calculate-shards.result == 'success' && needs.build-test-image.result == 'success' && (needs.purge-branch.result == 'success' || needs.purge-branch.result == 'skipped')
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false  # Continue running other shards even if one fails
      matrix: ${{ fromJson(needs.calculate-shards.outputs.matrix) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 2

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull Docker image
        run: |
          # Use the deps-specific tag for better caching
          IMAGE_TAG="ghcr.io/${{ github.repository }}/nala-tests:${{ needs.build-test-image.outputs.deps-tag }}"
          echo "Pulling image: $IMAGE_TAG"
          docker pull $IMAGE_TAG
          
          # Tag it as milo-nala-tests:latest for compatibility
          docker tag $IMAGE_TAG milo-nala-tests:latest
          docker image ls

      - name: Download shard assignments
        id: download-shards
        run: |
          # Try to download shard assignments artifact
          echo "Attempting to download shard-assignments artifact..."
          
          # Use gh CLI to download artifact (more reliable than the action)
          if gh run download ${{ github.run_id }} --repo ${{ github.repository }} --name shard-assignments --dir ./ 2>/dev/null; then
            echo "‚úì Successfully downloaded shard-assignments"
            echo "outcome=success" >> $GITHUB_OUTPUT
          else
            echo "‚úó No shard-assignments artifact found (using standard sharding)"
            echo "outcome=failure" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Set test files for shard
        run: |
          # Check if we successfully downloaded shard assignments
          if [ "${{ steps.download-shards.outcome }}" == "success" ] && [ -f shard-assignments.json ]; then
            # Get test files for this shard
            TEST_FILES=$(jq -r '.shards."${{ matrix.shard }}"[]' shard-assignments.json 2>/dev/null | tr '\n' ' ')
            if [ ! -z "$TEST_FILES" ] && [ "$TEST_FILES" != "null" ]; then
              echo "TEST_FILES=$TEST_FILES" >> $GITHUB_ENV
              echo "Running specific test files for shard ${{ matrix.shard }}: $TEST_FILES"
            else
              echo "No test files found for shard ${{ matrix.shard }}, will use standard sharding"
            fi
          else
            echo "No shard assignments available, will use standard sharding"
            echo "Download outcome: ${{ steps.download-shards.outcome }}"
          fi

      - name: Run Nala Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
        run: |
          docker run --name nala-test-container-${{ matrix.shard }} \
            --ipc=host \
            -v ${{ github.workspace }}/nala:/workspace/nala:ro \
            -v ${{ github.workspace }}/test-results:/workspace/test-results \
            -v ${{ github.workspace }}/test-html-results:/workspace/test-html-results \
            -v ${{ github.workspace }}/playwright-report:/workspace/playwright-report \
            -e GITHUB_ACTION_PATH=/workspace \
            -e GITHUB_REF=${{ github.ref }} \
            -e GITHUB_HEAD_REF=${{ github.event.pull_request.head.ref }} \
            -e GITHUB_REPOSITORY="${{ github.repository }}" \
            -e labels="${{ join(github.event.pull_request.labels.*.name, ' ') }}" \
            -e branch="${{ github.event.pull_request.head.ref }}" \
            -e repoName="${{ github.repository }}" \
            -e prUrl="${{ github.event.pull_request.head.repo.html_url }}" \
            -e prOrg="${{ github.event.pull_request.head.repo.owner.login }}" \
            -e prRepo="${{ github.event.pull_request.head.repo.name }}" \
            -e prBranch="${{ github.event.pull_request.head.ref }}" \
            -e prBaseBranch="${{ github.event.pull_request.base.ref }}" \
            -e IMS_EMAIL="${{ secrets.IMS_EMAIL }}" \
            -e IMS_PASS="${{ secrets.IMS_PASS }}" \
            -e SHARD_INDEX="${{ matrix.shard }}" \
            -e SHARD_TOTAL="${{ needs.calculate-shards.outputs.shard-count }}" \
            -e TEST_FILES="${{ env.TEST_FILES }}" \
            milo-nala-tests:latest || EXIT_CODE=$?
          
          # Copy test-results.json from container regardless of test outcome
          echo "Copying test results from container..."
          
          # Debug: List files in workspace
          echo "Files in container /workspace:"
          docker exec nala-test-container-${{ matrix.shard }} ls -la /workspace/ | head -20 || true
          
          # Also check if test-results.json exists in container
          echo "Checking for test-results.json in container..."
          docker exec nala-test-container-${{ matrix.shard }} ls -la /workspace/test-results.json 2>&1 || echo "File not found"
          
          # Copy the JSON file
          docker cp nala-test-container-${{ matrix.shard }}:/workspace/test-results.json ./test-results.json 2>/dev/null || echo "No test-results.json found in container"
          
          # Debug: Check current directory after copy
          echo "Files in current directory after copy:"
          ls -la test-results.json 2>&1 || echo "test-results.json not in current directory"
          
          # Clean up container
          docker rm nala-test-container-${{ matrix.shard }} || true
          
          # Check if we got the JSON file
          if [ -f test-results.json ]; then
            echo "‚úì Successfully extracted test-results.json ($(stat -f%z test-results.json 2>/dev/null || stat -c%s test-results.json) bytes)"
          else
            echo "‚úó test-results.json not found - tests may have failed before generating results"
          fi
          
          # Exit with original exit code if tests failed
          if [ ! -z "$EXIT_CODE" ] && [ "$EXIT_CODE" -ne 0 ]; then
            exit $EXIT_CODE
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-shard-${{ matrix.shard }}
          path: |
            test-results/
            playwright-report/
            test-html-results/
            nala-results.json
            test-results.json
          retention-days: 7
          if-no-files-found: warn

  # Merge and report combined results
  merge-test-results:
    name: Merge Test Results
    needs: [calculate-shards, run-nala-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Set up Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Restore previous timing data
        uses: actions/cache@v3
        with:
          path: previous-timings.json
          key: test-timings-v1-${{ github.sha }}
          restore-keys: |
            test-timings-v1-

      - name: Verify merge scripts exist
        run: |
          echo "Current directory: $(pwd)"
          echo "Checking for merge scripts:"
          ls -la nala/utils/*.js | grep -E "(merge-json|analyze-test|calculate-weighted)" || echo "Scripts not found!"

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: all-shards
          pattern: test-results-shard-*
          merge-multiple: true

      - name: Merge HTML reports
        run: |
          echo "Merging HTML reports from ${{ needs.calculate-shards.outputs.shard-count }} shards..."
          
          # Find all HTML reports
          REPORT_DIRS=$(find all-shards -name "playwright-report" -type d | tr '\n' ' ')
          
          if [ ! -z "$REPORT_DIRS" ]; then
            # Merge reports and output to a specific directory without opening
            PLAYWRIGHT_HTML_OPEN=never npx playwright merge-reports ${REPORT_DIRS} --reporter=html || true
          fi

      - name: Create summary report
        run: |
          echo "## Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Total shards:** ${{ needs.calculate-shards.outputs.shard-count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count results from each shard
          echo "### Shard Results" >> $GITHUB_STEP_SUMMARY
          for dir in all-shards/test-results-shard-*/; do
            if [ -d "$dir" ]; then
              SHARD_NUM=$(basename "$dir" | sed 's/test-results-shard-//')
              echo "- **Shard $SHARD_NUM:** " >> $GITHUB_STEP_SUMMARY
              
              # Try to extract test counts if available
              if [ -f "$dir/nala-results.json" ]; then
                echo "  ‚úÖ Results collected" >> $GITHUB_STEP_SUMMARY
              else
                echo "  ‚ö†Ô∏è No results file found" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
          
          # Performance metrics
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Performance" >> $GITHUB_STEP_SUMMARY
          SHARD_COUNT=${{ needs.calculate-shards.outputs.shard-count }}
          TIME_SAVED=$((($SHARD_COUNT - 1) * 100 / $SHARD_COUNT))
          echo "- **Estimated time reduction:** ~${TIME_SAVED}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallelization factor:** ${SHARD_COUNT}x" >> $GITHUB_STEP_SUMMARY

      - name: Analyze test timings
        if: always()
        run: |
          echo "### Analyzing test timings from JSON reports" >> $GITHUB_STEP_SUMMARY
          
          # Find all JSON test result files
          JSON_FILES=$(find all-shards -name "test-results.json" -type f 2>/dev/null | tr '\n' ' ')
          
          # Debug: Check what files we found
          echo "Found $(echo $JSON_FILES | wc -w) JSON test result files"
          
          if [ ! -z "$JSON_FILES" ]; then
            # List files for debugging
            echo "JSON files found:"
            for f in $JSON_FILES; do
              echo "  - $f (size: $(stat -f%z "$f" 2>/dev/null || stat -c%s "$f" 2>/dev/null || echo "unknown") bytes)"
            done
            
            # Merge JSON reports
            echo "Merging JSON reports..."
            if node nala/utils/merge-json-reports.js $JSON_FILES > merged-results.json; then
              echo "‚úì Successfully merged reports"
              echo "Merged report size: $(stat -f%z merged-results.json 2>/dev/null || stat -c%s merged-results.json) bytes"
            else
              echo "‚úó Failed to merge reports"
            fi
            
            # Check if we have previous timing data from cache
            if [ -f previous-timings.json ]; then
              echo "Using cached previous timing data"
              echo "Previous timing data size: $(stat -f%z previous-timings.json 2>/dev/null || stat -c%s previous-timings.json) bytes"
            else
              echo "No previous timing data found in cache"
            fi
            
            # Analyze timings - always try to create something
            if [ -f merged-results.json ]; then
              # Debug: Show merged results structure
              echo "Merged results preview:"
              head -c 500 merged-results.json || true
              echo ""
              
              if [ -f previous-timings.json ]; then
                echo "Merging with previous timing data..."
                if ! node nala/utils/analyze-test-timings.js \
                  --input merged-results.json \
                  --previous previous-timings.json \
                  --output test-timings.json; then
                  echo "ERROR: Failed to analyze with previous data"
                  # Try without previous data as fallback
                  echo "Retrying without previous data..."
                  node nala/utils/analyze-test-timings.js \
                    --input merged-results.json \
                    --output test-timings.json || echo "ERROR: Failed again"
                fi
              else
                echo "Creating new timing data..."
                if ! node nala/utils/analyze-test-timings.js \
                  --input merged-results.json \
                  --output test-timings.json; then
                  echo "ERROR: Failed to create new timing data"
                  # Show error details
                  echo "Node.js version: $(node --version)"
                  echo "Current directory: $(pwd)"
                  echo "Files in directory: $(ls -la | head -10)"
                fi
              fi
            else
              echo "ERROR: merged-results.json not found!"
            fi
            
            # Add timing summary to workflow summary if file was created
            if [ -f test-timings.json ]; then
              echo "‚úì Timing data generated successfully"
              node nala/utils/analyze-test-timings.js --summary test-timings.json >> $GITHUB_STEP_SUMMARY || true
            else
              echo "‚ö†Ô∏è No timing data generated" >> $GITHUB_STEP_SUMMARY
              
              # Create a minimal timing file to bootstrap the process
              echo "Creating minimal timing data to bootstrap..."
              echo '{
                "timings": {},
                "lastUpdated": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
                "totalFiles": 0,
                "totalDuration": 0,
                "newFiles": []
              }' > test-timings.json
            fi
          else
            echo "No JSON test results found for timing analysis" >> $GITHUB_STEP_SUMMARY
            echo "This is expected if all test shards failed" >> $GITHUB_STEP_SUMMARY
            
            # Create empty timing file to ensure we have something for next run
            echo "Creating empty timing data file..."
            echo '{
              "timings": {},
              "lastUpdated": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
              "totalFiles": 0,
              "totalDuration": 0,
              "newFiles": []
            }' > test-timings.json
          fi

      - name: Save test timing data to cache
        if: always() && hashFiles('test-timings.json') != ''
        uses: actions/cache@v3
        with:
          path: test-timings.json
          key: test-timings-v1-${{ github.sha }}

      - name: Upload merged results
        uses: actions/upload-artifact@v4
        with:
          name: merged-playwright-report
          path: |
            playwright-report/
            all-shards/
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        continue-on-error: true
        with:
          script: |
            const shardCount = ${{ needs.calculate-shards.outputs.shard-count }};
            const comment = `## üé≠ E2E Test Results
            
            Tests completed across **${shardCount} parallel runners**
            
            | Status | Details |
            |--------|---------|
            | ‚úÖ Parallelization | ${shardCount} shards |
            | üìä Reports | [View Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |
            | ‚è±Ô∏è Time Saved | ~${Math.round((shardCount - 1) * 100 / shardCount)}% faster |
            
            [View Full Summary](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
