name: Run Nala Tests

on:
  push:
    branches:
      - stage
      - main
  pull_request:
    branches:
      - stage
      - main
    types: [opened, synchronize, reopened]
  
  workflow_dispatch:
    inputs:
      max_shards:
        description: 'Maximum number of parallel shards (2-10)'
        required: false
        default: '6'
        type: string

jobs:
  # Calculate optimal shard count based on test files
  calculate-shards:
    name: Calculate Test Shards
    runs-on: ubuntu-latest
    outputs:
      shard-count: ${{ steps.calculate.outputs.count }}
      matrix: ${{ steps.calculate.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Setup Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Download previous test timing data
        uses: actions/download-artifact@v4
        with:
          name: test-timings
          path: ./
        continue-on-error: true

      - name: Calculate optimal shard count
        id: calculate
        run: |
          # Count test files
          TEST_COUNT=$(find nala -name "*.test.js" | wc -l)
          echo "Found $TEST_COUNT test files"
          
          # Get max shards from input (default to 6 for auto runs)
          MAX_SHARDS=${{ inputs.max_shards }}
          MAX_SHARDS=${MAX_SHARDS:-6}
          
          # Check if we have timing data for weighted distribution
          if [ -f test-timings.json ]; then
            echo "Using weighted distribution based on test execution times"
            
            # Calculate weighted shards
            node nala/utils/calculate-weighted-shards.js \
              --timing-data test-timings.json \
              --max-shards $MAX_SHARDS \
              --output shard-assignments.json
            
            # Extract shard count from output
            OPTIMAL_SHARDS=$(jq -r '.shardCount' shard-assignments.json)
            
            # Generate distribution summary
            echo "## Test Sharding Configuration (Weighted)" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Distribution by Shard:" >> $GITHUB_STEP_SUMMARY
            echo "| Shard | Tests | Duration |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|-------|----------|" >> $GITHUB_STEP_SUMMARY
            
            # Add distribution details
            jq -r '.distribution[] | "| \(.shard) | \(.testCount) | \(.duration)s |"' shard-assignments.json >> $GITHUB_STEP_SUMMARY
          else
            echo "No timing data found, using count-based distribution"
            
            # Calculate optimal shard count (5-8 test files per shard)
            OPTIMAL_SHARDS=$((TEST_COUNT / 6))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS < 2 ? 2 : OPTIMAL_SHARDS))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS > MAX_SHARDS ? MAX_SHARDS : OPTIMAL_SHARDS))
            
            echo "## Test Sharding Configuration" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "- **Tests per shard:** ~$((TEST_COUNT / OPTIMAL_SHARDS))" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "Using $OPTIMAL_SHARDS shards for $TEST_COUNT test files"
          echo "count=$OPTIMAL_SHARDS" >> $GITHUB_OUTPUT
          
          # Create matrix JSON
          SHARDS_JSON=""
          for i in $(seq 1 $OPTIMAL_SHARDS); do
            if [ $i -eq 1 ]; then
              SHARDS_JSON="$i"
            else
              SHARDS_JSON="$SHARDS_JSON,$i"
            fi
          done
          MATRIX="{\"shard\":[$SHARDS_JSON]}"
          echo "Debug: Generated matrix: $MATRIX"
          printf "matrix=%s\n" "$MATRIX" >> $GITHUB_OUTPUT

      - name: Upload shard assignments
        if: hashFiles('shard-assignments.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: shard-assignments
          path: shard-assignments.json
          retention-days: 1

  # Purge branch before running tests
  purge-branch:
    name: Purge Branch Cache
    runs-on: ubuntu-latest
    steps:
      - name: Purge branch
        run: |
          # Determine branch name based on event type
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            FEATURE_BRANCH="${{ github.event.pull_request.head.ref }}"
            ORG="${{ github.event.pull_request.head.repo.owner.login }}"
            REPO="${{ github.event.pull_request.head.repo.name }}"
          else
            # For push events (main/stage)
            FEATURE_BRANCH="${{ github.ref_name }}"
            ORG="${{ github.repository_owner }}"
            REPO="${{ github.event.repository.name }}"
          fi
          
          # Replace "/" characters in branch name with "-"
          FEATURE_BRANCH=$(echo "$FEATURE_BRANCH" | sed 's/\//-/g')
          
          echo "Event: ${{ github.event_name }}"
          echo "Organization: $ORG"
          echo "Repository: $REPO"
          echo "Branch: $FEATURE_BRANCH"
          
          # Skip purge for main branch (it doesn't need purging)
          if [[ "$FEATURE_BRANCH" == "main" ]]; then
            echo "‚ÑπÔ∏è Skipping purge for main branch"
            exit 0
          fi
          
          echo "Purging branch: $FEATURE_BRANCH"
          PURGE_URL="https://admin.hlx.page/code/$ORG/$REPO/$FEATURE_BRANCH/*"
          
          echo "Executing: curl -si -X POST \"$PURGE_URL\""
          PURGE_RESPONSE=$(curl -si -X POST "$PURGE_URL")
          
          # Check if the purge was successful
          if echo "$PURGE_RESPONSE" | grep -q "202"; then
            echo "‚úÖ Branch $FEATURE_BRANCH successfully purged"
            echo "Waiting 10 seconds for purge to complete..."
            sleep 10
          else
            echo "‚ùå Failed to purge branch $FEATURE_BRANCH"
            echo "Response: $PURGE_RESPONSE"
            # Don't fail the workflow if purge fails, just warn
            echo "::warning::Branch purge failed but continuing with tests"
          fi

  # Build Docker image with dependency caching
  build-test-image:
    name: Build Test Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
      deps-tag: ${{ steps.deps-tag.outputs.tag }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate image metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}/nala-tests
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}

      - name: Check if image exists
        id: check
        run: |
          # Get the deps tag to check if we need to rebuild
          DEPS_TAG="ghcr.io/${{ github.repository }}/nala-tests:deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "Checking for existing image: $DEPS_TAG"
          
          if docker manifest inspect $DEPS_TAG > /dev/null 2>&1; then
            echo "Image exists with current dependencies, skipping build"
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "existing_tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          else
            echo "Image not found or dependencies changed, building new image"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Build and push Docker image
        if: steps.check.outputs.exists != 'true'
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.nala
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PLAYWRIGHT_VERSION=1.54.2

      - name: Export image reference
        id: deps-tag
        run: |
          DEPS_TAG="deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          
          if [[ "${{ steps.check.outputs.exists }}" == "true" ]]; then
            echo "IMAGE_REF=${{ steps.check.outputs.existing_tag }}" >> $GITHUB_ENV
          else
            echo "IMAGE_REF=ghcr.io/${{ github.repository }}/nala-tests@${{ steps.build.outputs.digest }}" >> $GITHUB_ENV
          fi
          echo "Using image: $IMAGE_REF"

  # Parallel test execution using the cached image
  run-nala-tests:
    name: E2E Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
    needs: [calculate-shards, build-test-image, purge-branch]
    if: always() && !cancelled() && needs.calculate-shards.result == 'success' && needs.build-test-image.result == 'success' && (needs.purge-branch.result == 'success' || needs.purge-branch.result == 'skipped')
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false  # Continue running other shards even if one fails
      matrix: ${{ fromJson(needs.calculate-shards.outputs.matrix) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 2

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull Docker image
        run: |
          # Use the deps-specific tag for better caching
          IMAGE_TAG="ghcr.io/${{ github.repository }}/nala-tests:${{ needs.build-test-image.outputs.deps-tag }}"
          echo "Pulling image: $IMAGE_TAG"
          docker pull $IMAGE_TAG
          
          # Tag it as milo-nala-tests:latest for compatibility
          docker tag $IMAGE_TAG milo-nala-tests:latest
          docker image ls

      - name: Download shard assignments
        uses: actions/download-artifact@v4
        with:
          name: shard-assignments
          path: ./
        continue-on-error: true

      - name: Set test files for shard
        run: |
          if [ -f shard-assignments.json ]; then
            # Get test files for this shard
            TEST_FILES=$(jq -r '.shards."${{ matrix.shard }}"[]' shard-assignments.json | tr '\n' ' ')
            echo "TEST_FILES=$TEST_FILES" >> $GITHUB_ENV
            echo "Running specific test files for shard ${{ matrix.shard }}: $TEST_FILES"
          else
            echo "No shard assignments found, will use standard sharding"
          fi

      - name: Run Nala Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
        run: |
          docker run --rm \
            --ipc=host \
            -v ${{ github.workspace }}/nala:/workspace/nala:ro \
            -v ${{ github.workspace }}/test-results:/workspace/test-results \
            -v ${{ github.workspace }}/test-html-results:/workspace/test-html-results \
            -v ${{ github.workspace }}/playwright-report:/workspace/playwright-report \
            -e GITHUB_ACTION_PATH=/workspace \
            -e GITHUB_REF=${{ github.ref }} \
            -e GITHUB_HEAD_REF=${{ github.event.pull_request.head.ref }} \
            -e GITHUB_REPOSITORY="${{ github.repository }}" \
            -e labels="${{ join(github.event.pull_request.labels.*.name, ' ') }}" \
            -e branch="${{ github.event.pull_request.head.ref }}" \
            -e repoName="${{ github.repository }}" \
            -e prUrl="${{ github.event.pull_request.head.repo.html_url }}" \
            -e prOrg="${{ github.event.pull_request.head.repo.owner.login }}" \
            -e prRepo="${{ github.event.pull_request.head.repo.name }}" \
            -e prBranch="${{ github.event.pull_request.head.ref }}" \
            -e prBaseBranch="${{ github.event.pull_request.base.ref }}" \
            -e IMS_EMAIL="${{ secrets.IMS_EMAIL }}" \
            -e IMS_PASS="${{ secrets.IMS_PASS }}" \
            -e SHARD_INDEX="${{ matrix.shard }}" \
            -e SHARD_TOTAL="${{ needs.calculate-shards.outputs.shard-count }}" \
            -e TEST_FILES="${{ env.TEST_FILES }}" \
            milo-nala-tests:latest

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-shard-${{ matrix.shard }}
          path: |
            test-results/
            playwright-report/
            test-html-results/
            nala-results.json
            test-results.json
          retention-days: 7

  # Merge and report combined results
  merge-test-results:
    name: Merge Test Results
    needs: [calculate-shards, run-nala-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Set up Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: all-shards
          pattern: test-results-shard-*
          merge-multiple: true

      - name: Install merge tools
        run: npm install -g playwright-merge-html-reports

      - name: Merge HTML reports
        run: |
          echo "Merging HTML reports from ${{ needs.calculate-shards.outputs.shard-count }} shards..."
          
          # Find all HTML reports
          REPORT_DIRS=$(find all-shards -name "playwright-report" -type d | tr '\n' ' ')
          
          if [ ! -z "$REPORT_DIRS" ]; then
            # Merge reports and output to a specific directory without opening
            PLAYWRIGHT_HTML_OPEN=never npx playwright merge-reports ${REPORT_DIRS} --reporter=html || true
          fi

      - name: Create summary report
        run: |
          echo "## Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Total shards:** ${{ needs.calculate-shards.outputs.shard-count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count results from each shard
          echo "### Shard Results" >> $GITHUB_STEP_SUMMARY
          for dir in all-shards/test-results-shard-*/; do
            if [ -d "$dir" ]; then
              SHARD_NUM=$(basename "$dir" | sed 's/test-results-shard-//')
              echo "- **Shard $SHARD_NUM:** " >> $GITHUB_STEP_SUMMARY
              
              # Try to extract test counts if available
              if [ -f "$dir/nala-results.json" ]; then
                echo "  ‚úÖ Results collected" >> $GITHUB_STEP_SUMMARY
              else
                echo "  ‚ö†Ô∏è No results file found" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
          
          # Performance metrics
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Performance" >> $GITHUB_STEP_SUMMARY
          SHARD_COUNT=${{ needs.calculate-shards.outputs.shard-count }}
          TIME_SAVED=$((($SHARD_COUNT - 1) * 100 / $SHARD_COUNT))
          echo "- **Estimated time reduction:** ~${TIME_SAVED}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallelization factor:** ${SHARD_COUNT}x" >> $GITHUB_STEP_SUMMARY

      - name: Analyze test timings
        run: |
          echo "### Analyzing test timings from JSON reports" >> $GITHUB_STEP_SUMMARY
          
          # Find all JSON test result files
          JSON_FILES=$(find all-shards -name "test-results.json" -type f | tr '\n' ' ')
          
          if [ ! -z "$JSON_FILES" ]; then
            # Merge JSON reports
            node nala/utils/merge-json-reports.js $JSON_FILES > merged-results.json
            
            # Download previous timing data if exists
            curl -s -o previous-timings.json \
              https://github.com/${{ github.repository }}/releases/download/test-timings/test-timings.json || true
            
            # Analyze timings
            if [ -f previous-timings.json ]; then
              node nala/utils/analyze-test-timings.js \
                --input merged-results.json \
                --previous previous-timings.json \
                --output test-timings.json
            else
              node nala/utils/analyze-test-timings.js \
                --input merged-results.json \
                --output test-timings.json
            fi
            
            # Add timing summary to workflow summary
            node nala/utils/analyze-test-timings.js --summary test-timings.json >> $GITHUB_STEP_SUMMARY
          else
            echo "No JSON test results found for timing analysis" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload test timing data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-timings
          path: test-timings.json
          retention-days: 90

      - name: Upload merged results
        uses: actions/upload-artifact@v4
        with:
          name: merged-playwright-report
          path: |
            playwright-report/
            all-shards/
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        continue-on-error: true
        with:
          script: |
            const shardCount = ${{ needs.calculate-shards.outputs.shard-count }};
            const comment = `## üé≠ E2E Test Results
            
            Tests completed across **${shardCount} parallel runners**
            
            | Status | Details |
            |--------|---------|
            | ‚úÖ Parallelization | ${shardCount} shards |
            | üìä Reports | [View Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |
            | ‚è±Ô∏è Time Saved | ~${Math.round((shardCount - 1) * 100 / shardCount)}% faster |
            
            [View Full Summary](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
