name: Run Nala Tests

on:
  push:
    branches:
      - stage
      - main
  pull_request:
    branches:
      - stage
      - main
    types: [opened, synchronize, reopened]
  
  workflow_dispatch:
    inputs:
      max_shards:
        description: 'Maximum number of parallel shards (2-20)'
        required: false
        default: '10'
        type: string
      target_duration:
        description: 'Target duration per shard in seconds (default: 120)'
        required: false
        default: '120'
        type: string

jobs:
  # Calculate optimal shard count based on test files
  calculate-shards:
    name: Calculate Test Shards
    runs-on: ubuntu-latest
    outputs:
      shard-count: ${{ steps.calculate.outputs.count }}
      matrix: ${{ steps.calculate.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Setup Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Restore test timing data
        id: cache-restore
        uses: actions/cache/restore@v3
        with:
          path: test-timings.json
          # Look for timing data from the current branch only
          key: test-timings-${{ github.ref_name }}-${{ github.run_number }}
          restore-keys: |
            test-timings-${{ github.ref_name }}-
      
      - name: Check and clean timing data
        run: |
          # Show which cache key was actually used
          echo "Cache restore result: ${{ steps.cache-restore.outputs.cache-hit }}"
          echo "Cache key used: ${{ steps.cache-restore.outputs.cache-matched-key || 'No exact match' }}"
          echo "Primary key attempted: test-timings-${{ github.ref_name }}-${{ github.run_number }}"
          
          # Check if default timings are newer than cached timings
          if [ -f test-timings.json ] && [ -f nala/utils/default-test-timings.json ]; then
            CACHED_DATE=$(jq -r '.lastUpdated // "1970-01-01T00:00:00Z"' test-timings.json)
            DEFAULT_DATE=$(jq -r '.lastUpdated // "1970-01-01T00:00:00Z"' nala/utils/default-test-timings.json)
            
            echo "Cached timing date: $CACHED_DATE"
            echo "Default timing date: $DEFAULT_DATE"
            
            # Convert ISO 8601 dates to epoch for comparison
            # Remove milliseconds and Z for better compatibility
            CACHED_DATE_CLEAN=$(echo "$CACHED_DATE" | sed 's/\.[0-9]*Z$//')
            DEFAULT_DATE_CLEAN=$(echo "$DEFAULT_DATE" | sed 's/\.[0-9]*Z$//')
            
            # GNU date (Linux/GitHub Actions)
            CACHED_EPOCH=$(date -d "$CACHED_DATE_CLEAN" +%s 2>/dev/null || echo "0")
            DEFAULT_EPOCH=$(date -d "$DEFAULT_DATE_CLEAN" +%s 2>/dev/null || echo "0")
            
            echo "Cached epoch: $CACHED_EPOCH, Default epoch: $DEFAULT_EPOCH"
            
            if [ "$DEFAULT_EPOCH" -gt "$CACHED_EPOCH" ]; then
              echo "Default timings are newer than cached timings, using defaults"
              cp nala/utils/default-test-timings.json test-timings.json
            else
              echo "Cached timings are up to date"
            fi
          elif [ ! -f test-timings.json ] && [ -f nala/utils/default-test-timings.json ]; then
            echo "No cached timing data found, using defaults"
            cp nala/utils/default-test-timings.json test-timings.json
          fi
          
          if [ -f test-timings.json ]; then
            echo "Successfully loaded timing data"
            echo "File size: $(stat -f%z test-timings.json 2>/dev/null || stat -c%s test-timings.json) bytes"
            
            # Clean up stale entries for files that no longer exist
            echo "Cleaning up stale timing entries..."
            
            # Get list of current test files
            CURRENT_TESTS=$(find nala -name "*.test.js" -type f | sed 's|^\./||' | sort)
            
            # Create a cleaned version of the timing file
            jq --arg tests "$CURRENT_TESTS" '
              .timings as $timings |
              ($tests | split("\n") | map(select(. != "")) | map({(.): true}) | add) as $current |
              .timings = ($timings | with_entries(select(.key as $k | $current | has($k)))) |
              .lastUpdated = (now | todate) |
              .totalFiles = (.timings | keys | length)
            ' test-timings.json > test-timings-cleaned.json
            
            # Check if any entries were removed
            ORIGINAL_COUNT=$(jq -r '.timings | keys | length' test-timings.json)
            NEW_COUNT=$(jq -r '.timings | keys | length' test-timings-cleaned.json)
            REMOVED=$((ORIGINAL_COUNT - NEW_COUNT))
            
            if [ $REMOVED -gt 0 ]; then
              echo "Removed $REMOVED stale timing entries"
              mv test-timings-cleaned.json test-timings.json
            else
              echo "No stale entries found"
              rm -f test-timings-cleaned.json
            fi
            
            # Show sample of timing data to verify it's not just defaults
            echo "Sample timing entries (first 5):"
            jq -r '.timings | to_entries[:5] | .[] | "  \(.key): \(.value)ms"' test-timings.json 2>/dev/null || true
            echo "Last updated: $(jq -r '.lastUpdated' test-timings.json 2>/dev/null || echo 'unknown')"
          else
            echo "No previous timing data found, will use default baseline timings"
          fi

      - name: Calculate optimal shard count
        id: calculate
        run: |
          # Count test files
          TEST_COUNT=$(find nala -name "*.test.js" | wc -l)
          echo "Found $TEST_COUNT test files"
          
          # Get max shards from input (default to 10 for auto runs)
          MAX_SHARDS=${{ inputs.max_shards }}
          MAX_SHARDS=${MAX_SHARDS:-10}
          
          # Check if we have timing data for weighted distribution
          if [ -f test-timings.json ]; then
            echo "Using weighted distribution based on test execution times"
            
            # Set target duration per shard (in seconds)
            # Use workflow input if provided, otherwise default to 120 seconds (2 minutes)
            TARGET_DURATION=${{ inputs.target_duration }}
            export SHARD_TARGET_DURATION="${TARGET_DURATION:-120}"
            echo "Target duration per shard: ${SHARD_TARGET_DURATION}s"
            
            # Calculate weighted shards
            node nala/utils/calculate-weighted-shards.js \
              --timing-data test-timings.json \
              --max-shards $MAX_SHARDS \
              --output shard-assignments.json
            
            # Extract shard count from output
            OPTIMAL_SHARDS=$(jq -r '.shardCount' shard-assignments.json)
            
            # Generate distribution summary
            echo "## Test Sharding Configuration (Weighted)" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "- **Target duration per shard:** ${SHARD_TARGET_DURATION}s" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Distribution by Shard:" >> $GITHUB_STEP_SUMMARY
            echo "| Shard | Tests | Est. Duration | Balance |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|-------|---------------|---------|" >> $GITHUB_STEP_SUMMARY
            
            # Add distribution overview
            jq -r '.distribution[] | "| Shard \(.shard) | \(.testCount) | ~\(.duration)s | \(.percentage)% |"' shard-assignments.json >> $GITHUB_STEP_SUMMARY
            
            # Add detailed breakdown for each shard
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary>📋 Detailed Test Distribution (click to expand)</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Loop through each shard and show its test files
            for shard in $(seq 1 $OPTIMAL_SHARDS); do
              echo "#### Shard $shard" >> $GITHUB_STEP_SUMMARY
              
              # Get test files and their durations for this shard
              echo '```' >> $GITHUB_STEP_SUMMARY
              jq -r --arg s "$shard" '.shards[$s][]' shard-assignments.json | while read -r file; do
                # Get duration for this file from expectedDurations or timing data
                DURATION_MS=$(jq -r --arg f "$file" '.timings[$f] // 15000' test-timings.json 2>/dev/null || echo "15000")
                DURATION_S=$(echo "scale=1; $DURATION_MS / 1000" | bc 2>/dev/null || echo "15.0")
                echo "  ${file##*/} (~${DURATION_S}s)" >> $GITHUB_STEP_SUMMARY
              done
              echo '```' >> $GITHUB_STEP_SUMMARY
              
              # Show total expected duration for this shard
              SHARD_DURATION=$(jq -r --arg s "$shard" '.expectedDurations[$s] // 0' shard-assignments.json)
              SHARD_DURATION_S=$(echo "scale=1; $SHARD_DURATION / 1000" | bc 2>/dev/null || echo "0")
              echo "_Total estimated duration: ~${SHARD_DURATION_S}s_" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            done
            
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          else
            echo "No timing data found, using count-based distribution"
            
            # Calculate optimal shard count (5-8 test files per shard)
            OPTIMAL_SHARDS=$((TEST_COUNT / 6))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS < 2 ? 2 : OPTIMAL_SHARDS))
            OPTIMAL_SHARDS=$((OPTIMAL_SHARDS > MAX_SHARDS ? MAX_SHARDS : OPTIMAL_SHARDS))
            
            echo "## Test Sharding Configuration" >> $GITHUB_STEP_SUMMARY
            echo "- **Test files found:** $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Shards to use:** $OPTIMAL_SHARDS" >> $GITHUB_STEP_SUMMARY
            echo "- **Tests per shard:** ~$((TEST_COUNT / OPTIMAL_SHARDS))" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "Using $OPTIMAL_SHARDS shards for $TEST_COUNT test files"
          echo "count=$OPTIMAL_SHARDS" >> $GITHUB_OUTPUT
          
          # Create matrix JSON
          SHARDS_JSON=""
          for i in $(seq 1 $OPTIMAL_SHARDS); do
            if [ $i -eq 1 ]; then
              SHARDS_JSON="$i"
            else
              SHARDS_JSON="$SHARDS_JSON,$i"
            fi
          done
          MATRIX="{\"shard\":[$SHARDS_JSON]}"
          echo "Debug: Generated matrix: $MATRIX"
          printf "matrix=%s\n" "$MATRIX" >> $GITHUB_OUTPUT
          
          # Debug: Check if shard-assignments.json exists
          if [ -f shard-assignments.json ]; then
            echo "✓ shard-assignments.json created successfully"
            echo "File size: $(stat -f%z shard-assignments.json 2>/dev/null || stat -c%s shard-assignments.json) bytes"
          else
            echo "✗ shard-assignments.json not found"
          fi

      - name: Upload shard assignments
        if: success() && hashFiles('shard-assignments.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: shard-assignments
          path: shard-assignments.json
          retention-days: 1
          if-no-files-found: warn

  # Purge branch before running tests
  purge-branch:
    name: Purge Branch Cache
    runs-on: ubuntu-latest
    steps:
      - name: Purge branch
        run: |
          # Determine branch name based on event type
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            FEATURE_BRANCH="${{ github.event.pull_request.head.ref }}"
            ORG="${{ github.event.pull_request.head.repo.owner.login }}"
            REPO="${{ github.event.pull_request.head.repo.name }}"
          else
            # For push events (main/stage)
            FEATURE_BRANCH="${{ github.ref_name }}"
            ORG="${{ github.repository_owner }}"
            REPO="${{ github.event.repository.name }}"
          fi
          
          # Replace "/" characters in branch name with "-"
          FEATURE_BRANCH=$(echo "$FEATURE_BRANCH" | sed 's/\//-/g')
          
          echo "Event: ${{ github.event_name }}"
          echo "Organization: $ORG"
          echo "Repository: $REPO"
          echo "Branch: $FEATURE_BRANCH"
          
          # Skip purge for main branch (it doesn't need purging)
          if [[ "$FEATURE_BRANCH" == "main" ]]; then
            echo "ℹ️ Skipping purge for main branch"
            exit 0
          fi
          
          echo "Purging branch: $FEATURE_BRANCH"
          PURGE_URL="https://admin.hlx.page/code/$ORG/$REPO/$FEATURE_BRANCH/*"
          
          echo "Executing: curl -si -X POST \"$PURGE_URL\""
          PURGE_RESPONSE=$(curl -si -X POST "$PURGE_URL")
          
          # Check if the purge was successful
          if echo "$PURGE_RESPONSE" | grep -q "202"; then
            echo "✅ Branch $FEATURE_BRANCH successfully purged"
            echo "Waiting 10 seconds for purge to complete..."
            sleep 10
          else
            echo "❌ Failed to purge branch $FEATURE_BRANCH"
            echo "Response: $PURGE_RESPONSE"
            # Don't fail the workflow if purge fails, just warn
            echo "::warning::Branch purge failed but continuing with tests"
          fi

  # Build Docker image with dependency caching
  build-test-image:
    name: Build Test Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
      deps-tag: ${{ steps.deps-tag.outputs.tag }}
    steps:
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Calculate deps hash
        id: deps-hash
        run: |
          # Quick hash calculation without full checkout
          echo "Calculating dependencies hash..."
          
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          sparse-checkout: |
            package.json
            package-lock.json
            Dockerfile.nala

      - name: Set up Docker Build
        uses: docker/setup-buildx-action@v3

      - name: Generate image metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}/nala-tests
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}

      - name: Check if image exists
        id: check
        run: |
          # Get the deps tag to check if we need to rebuild
          DEPS_TAG="ghcr.io/${{ github.repository }}/nala-tests:deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "Checking for existing image: $DEPS_TAG"
          
          # Use docker manifest inspect to check if image exists (HEAD request, no download)
          if docker manifest inspect $DEPS_TAG > /dev/null 2>&1; then
            echo "✓ Image exists with current dependencies, skipping build"
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "existing_tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          else
            echo "⚠ Image not found or dependencies changed, building new image"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Build and push Docker image
        if: steps.check.outputs.exists != 'true'
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.nala
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PLAYWRIGHT_VERSION=1.54.2

      - name: Export image reference
        id: deps-tag
        run: |
          DEPS_TAG="deps-${{ hashFiles('package-lock.json', 'package.json', 'Dockerfile.nala') }}"
          echo "tag=$DEPS_TAG" >> $GITHUB_OUTPUT
          
          if [[ "${{ steps.check.outputs.exists }}" == "true" ]]; then
            echo "IMAGE_REF=${{ steps.check.outputs.existing_tag }}" >> $GITHUB_ENV
            echo "## ✅ Using Cached Image" >> $GITHUB_STEP_SUMMARY
            echo "Image: \`${{ steps.check.outputs.existing_tag }}\`" >> $GITHUB_STEP_SUMMARY
            echo "No rebuild needed - dependencies unchanged" >> $GITHUB_STEP_SUMMARY
          else
            echo "IMAGE_REF=ghcr.io/${{ github.repository }}/nala-tests@${{ steps.build.outputs.digest }}" >> $GITHUB_ENV
            echo "## 🔨 Built New Image" >> $GITHUB_STEP_SUMMARY
            echo "Image: \`ghcr.io/${{ github.repository }}/nala-tests@${{ steps.build.outputs.digest }}\`" >> $GITHUB_STEP_SUMMARY
            echo "Dependencies or Dockerfile changed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "Using image: $IMAGE_REF"

  # Parallel test execution using the cached image
  run-nala-tests:
    name: E2E Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
    needs: [calculate-shards, build-test-image, purge-branch]
    if: always() && !cancelled() && needs.calculate-shards.result == 'success' && needs.build-test-image.result == 'success' && (needs.purge-branch.result == 'success' || needs.purge-branch.result == 'skipped')
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository }}/nala-tests:${{ needs.build-test-image.outputs.deps-tag }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --ipc=host
    strategy:
      fail-fast: false  # Continue running other shards even if one fails
      matrix: ${{ fromJson(needs.calculate-shards.outputs.matrix) }}
    steps:
      # Note: Tests are included in the Docker image, but we still need
      # to checkout to get the latest test code for PRs
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
        with:
          fetch-depth: 1
          sparse-checkout: |
            nala/
            playwright.config.js

      - name: Download shard assignments
        id: download-shards
        run: |
          # Try to download shard assignments artifact
          echo "Attempting to download shard-assignments artifact..."
          
          # Use gh CLI to download artifact (more reliable than the action)
          if gh run download ${{ github.run_id }} --repo ${{ github.repository }} --name shard-assignments --dir ./ 2>/dev/null; then
            echo "✓ Successfully downloaded shard-assignments"
            echo "outcome=success" >> $GITHUB_OUTPUT
          else
            echo "✗ No shard-assignments artifact found (using standard sharding)"
            echo "outcome=failure" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Set test files for shard
        run: |
          # Check if we successfully downloaded shard assignments
          if [ "${{ steps.download-shards.outcome }}" == "success" ] && [ -f shard-assignments.json ]; then
            # Get test files for this shard
            TEST_FILES=$(jq -r '.shards."${{ matrix.shard }}"[]' shard-assignments.json 2>/dev/null | tr '\n' ' ')
            if [ ! -z "$TEST_FILES" ] && [ "$TEST_FILES" != "null" ]; then
              echo "TEST_FILES=$TEST_FILES" >> $GITHUB_ENV
              echo "Running specific test files for shard ${{ matrix.shard }}: $TEST_FILES"
            else
              echo "No test files found for shard ${{ matrix.shard }}, will use standard sharding"
            fi
          else
            echo "No shard assignments available, will use standard sharding"
            echo "Download outcome: ${{ steps.download-shards.outcome }}"
          fi

      - name: Run Nala Tests (Shard ${{ matrix.shard }}/${{ needs.calculate-shards.outputs.shard-count }})
        env:
          CI: true
          GITHUB_ACTION_PATH: ${{ github.workspace }}
          GITHUB_REF: ${{ github.ref }}
          GITHUB_HEAD_REF: ${{ github.event.pull_request.head.ref }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          labels: ${{ join(github.event.pull_request.labels.*.name, ' ') }}
          branch: ${{ github.event.pull_request.head.ref }}
          repoName: ${{ github.repository }}
          prUrl: ${{ github.event.pull_request.head.repo.html_url }}
          prOrg: ${{ github.event.pull_request.head.repo.owner.login }}
          prRepo: ${{ github.event.pull_request.head.repo.name }}
          prBranch: ${{ github.event.pull_request.head.ref }}
          prBaseBranch: ${{ github.event.pull_request.base.ref }}
          IMS_EMAIL: ${{ secrets.IMS_EMAIL }}
          IMS_PASS: ${{ secrets.IMS_PASS }}
          SHARD_INDEX: ${{ matrix.shard }}
          SHARD_TOTAL: ${{ needs.calculate-shards.outputs.shard-count }}
          CONTAINER: true
        run: |
          # Determine the test URL based on event type
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            # PR event - use PR branch
            BRANCH="${{ github.event.pull_request.head.ref }}"
            ORG="${{ github.event.pull_request.head.repo.owner.login }}"
            REPO="${{ github.event.pull_request.head.repo.name }}"
            BRANCH_CLEAN=$(echo "$BRANCH" | sed 's/\//-/g')
            export PR_BRANCH_LIVE_URL_GH="https://${BRANCH_CLEAN}--${REPO}--${ORG}.aem.live"
          elif [[ "${{ github.ref_name }}" == "main" ]]; then
            # Push to main - use production URL
            export PR_BRANCH_LIVE_URL_GH="https://milo.adobe.com"
          elif [[ "${{ github.ref_name }}" == "stage" ]]; then
            # Push to stage - use stage URL
            export PR_BRANCH_LIVE_URL_GH="https://stage--milo--adobecom.aem.live"
          else
            # Unknown event/branch - fail explicitly
            echo "ERROR: Unable to determine test URL for event '${{ github.event_name }}' on branch '${{ github.ref_name }}'"
            echo "This workflow only supports: pull_request events, or pushes to main/stage"
            exit 1
          fi
          
          echo "Event: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Test URL: $PR_BRANCH_LIVE_URL_GH"
          
          # Create directories for results
          mkdir -p test-results test-html-results playwright-report
          
          # Verify we're in the right directory with dependencies
          echo "Current directory: $(pwd)"
          echo "Node modules exists: $(test -d node_modules && echo 'yes' || echo 'no')"
          echo "Playwright test exists: $(test -d node_modules/@playwright/test && echo 'yes' || echo 'no')"
          
          # Make the test script executable
          chmod +x ./nala/utils/pr.run.sh
          
          # Run the test script with proper sharding
          if [ ! -z "${{ env.TEST_FILES }}" ]; then
            # Specific test files from weighted distribution
            ./nala/utils/pr.run.sh || EXIT_CODE=$?
          else
            # Standard sharding
            ./nala/utils/pr.run.sh || EXIT_CODE=$?
          fi
          
          # Rename the JSON file to shard-specific name
          if [ -f "test-results/test-results.json" ]; then
            SHARD_JSON="test-results/test-results-shard-${{ matrix.shard }}.json"
            mv "test-results/test-results.json" "$SHARD_JSON"
            echo "✓ Renamed test-results.json to $SHARD_JSON"
          fi
          
          # Exit with original exit code if tests failed
          if [ ! -z "$EXIT_CODE" ] && [ "$EXIT_CODE" -ne 0 ]; then
            echo "Tests failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-shard-${{ matrix.shard }}
          path: |
            test-results/test-results-shard-${{ matrix.shard }}.json
            playwright-report/
            test-html-results/
            nala-results.json
          retention-days: 7
          if-no-files-found: warn

  # Merge and report combined results
  merge-test-results:
    name: Merge Test Results
    needs: [calculate-shards, run-nala-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Set up Node.js
        uses: actions/setup-node@cdca7365b2dadb8aad0a33bc7601856ffabcc48e
        with:
          node-version: '20.x'

      - name: Restore previous timing data
        uses: actions/cache/restore@v3
        with:
          path: test-timings.json
          key: test-timings-restore-${{ github.run_number }}
          restore-keys: |
            test-timings-

      - name: Verify merge scripts exist
        run: |
          echo "Current directory: $(pwd)"
          echo "Checking for merge scripts:"
          ls -la nala/utils/*.js | grep -E "(merge-json|analyze-test|calculate-weighted)" || echo "Scripts not found!"

      - name: Download all test results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          path: all-shards
          pattern: test-results-shard-*
          merge-multiple: true

      - name: Merge HTML reports
        run: |
          echo "Merging HTML reports from ${{ needs.calculate-shards.outputs.shard-count }} shards..."
          
          # Find all HTML reports
          REPORT_DIRS=$(find all-shards -name "playwright-report" -type d | tr '\n' ' ')
          
          if [ ! -z "$REPORT_DIRS" ]; then
            # Merge reports and output to a specific directory without opening
            PLAYWRIGHT_HTML_OPEN=never npx playwright merge-reports ${REPORT_DIRS} --reporter=html || true
          fi

      - name: Create summary report
        run: |
          echo "## Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Total shards:** ${{ needs.calculate-shards.outputs.shard-count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count results from each shard
          echo "### Shard Results" >> $GITHUB_STEP_SUMMARY
          for dir in all-shards/test-results-shard-*/; do
            if [ -d "$dir" ]; then
              SHARD_NUM=$(basename "$dir" | sed 's/test-results-shard-//')
              echo "- **Shard $SHARD_NUM:** " >> $GITHUB_STEP_SUMMARY
              
              # Try to extract test counts if available
              if [ -f "$dir/nala-results.json" ]; then
                echo "  ✅ Results collected" >> $GITHUB_STEP_SUMMARY
              else
                echo "  ⚠️ No results file found" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
          
          # Performance metrics
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Performance" >> $GITHUB_STEP_SUMMARY
          SHARD_COUNT=${{ needs.calculate-shards.outputs.shard-count }}
          TIME_SAVED=$((($SHARD_COUNT - 1) * 100 / $SHARD_COUNT))
          echo "- **Estimated time reduction:** ~${TIME_SAVED}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallelization factor:** ${SHARD_COUNT}x" >> $GITHUB_STEP_SUMMARY

      - name: Update test timings
        if: always()
        run: |
          echo "### Updating test timings (key-value approach)" >> $GITHUB_STEP_SUMMARY
          
          # Check if we have cached timing data
          if [ -f test-timings.json ]; then
            echo "Starting with cached timing data"
            echo "Cached data size: $(stat -f%z test-timings.json 2>/dev/null || stat -c%s test-timings.json) bytes"
          else
            echo "Starting with fresh timing data"
          fi
          
          # Note: update-test-timings.js automatically removes entries for deleted test files
          
          # Find all shard-specific JSON files
          SHARD_FILES=$(find all-shards -name "test-results-shard-*.json" -type f 2>/dev/null)
          
          if [ ! -z "$SHARD_FILES" ]; then
            # Update timings from each shard
            PROCESSED=0
            for shard_file in $SHARD_FILES; do
              echo "Processing: $shard_file"
              if [ -s "$shard_file" ]; then
                if node nala/utils/update-test-timings.js "$shard_file" test-timings.json; then
                  PROCESSED=$((PROCESSED + 1))
                else
                  echo "Warning: Failed to process $shard_file"
                fi
              else
                echo "Warning: $shard_file is empty"
              fi
            done
            
            echo "Processed $PROCESSED shard files successfully"
            
            # Show summary
            if [ -f test-timings.json ]; then
              echo "✓ Timing data updated successfully"
              TOTAL_FILES=$(jq -r '.totalFiles // 0' test-timings.json)
              echo "Tracked test files: $TOTAL_FILES" >> $GITHUB_STEP_SUMMARY
              
              # Count actual test files for comparison
              ACTUAL_FILES=$(find nala -name "*.test.js" | wc -l)
              if [ "$TOTAL_FILES" -ne "$ACTUAL_FILES" ]; then
                echo "Note: Cleaned stale entries (actual files: $ACTUAL_FILES)" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          else
            echo "No test results found for timing update" >> $GITHUB_STEP_SUMMARY
            
            # Use default timings if available
            if [ ! -f test-timings.json ]; then
              echo "Creating timing file from defaults..."
              cp nala/utils/default-test-timings.json test-timings.json || echo '{
                "timings": {},
                "lastUpdated": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
                "totalFiles": 0
              }' > test-timings.json
            fi
          fi

      - name: Save test timing data to cache
        # Only save if workflow succeeded or failed (not cancelled) and timing file exists
        if: (success() || failure()) && hashFiles('test-timings.json') != ''
        uses: actions/cache/save@v3
        with:
          path: test-timings.json
          # Save with actual branch/PR ref - each branch maintains its own timing data
          key: test-timings-${{ github.ref_name }}-${{ github.run_number }}
      
      - name: Upload timing data as artifact
        # Also save as artifact for better persistence
        if: (success() || failure()) && hashFiles('test-timings.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: test-timings-${{ github.run_number }}
          path: test-timings.json
          retention-days: 30

      - name: Upload merged results
        uses: actions/upload-artifact@v4
        with:
          name: merged-playwright-report
          path: |
            playwright-report/
            all-shards/
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        continue-on-error: true
        with:
          script: |
            const shardCount = ${{ needs.calculate-shards.outputs.shard-count }};
            const comment = `## 🎭 E2E Test Results
            
            Tests completed across **${shardCount} parallel runners**
            
            | Status | Details |
            |--------|---------|
            | ✅ Parallelization | ${shardCount} shards |
            | 📊 Reports | [View Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |
            | ⏱️ Time Saved | ~${Math.round((shardCount - 1) * 100 / shardCount)}% faster |
            
            [View Full Summary](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
